{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtsHWi7KpR1x"
      },
      "source": [
        "# PyTorch ì‹œì‘í•˜ê¸°\n",
        "**AIKU í•™íšŒì› ì—¬ëŸ¬ë¶„!** ë”¥ëŸ¬ë‹ì„ í–¥í•œ ì—¬ì •ì— ë°œ ë“¤ì¸ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ˜„.\n",
        "\n",
        "í•™íšŒì› ì—¬ëŸ¬ë¶„ì´ ì•ìœ¼ë¡œ ë§ˆì£¼í•˜ê²Œ ë  ì—¬ëŸ¬ ì–´ë ¤ì›€ë“¤ì´ ìˆì„í…ë°, Deep Into Deepì˜ ìˆ˜ì—…ê³¼ ê³¼ì œê°€ ê·¸ ê¸¸ì— ì¡°ê¸ˆì€ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤.\n",
        "\n",
        "ë³¸ ê³¼ì œëŠ” CS231n, ê³ ë ¤ëŒ€í•™êµ ë”¥ëŸ¬ë‹ ìˆ˜ì—… ë“± ì—¬ëŸ¬ ì¢‹ì€ ê³¼ì œë“¤ì„ í˜¼í•©í•´ ë§Œë“¤ì–´ ì¡ŒìŒì„ ë¯¸ë¦¬ ì•Œë¦½ë‹ˆë‹¤. ê±°ì¸ì˜ ì–´ê¹¨ë¥¼ ë§Œë“¤ì–´ì¤€ ì—¬ëŸ¬ë¶„ ê°ì‚¬í•©ë‹ˆë‹¤!\n",
        "\n",
        "ë‹¤ì‹œ í•œ ë²ˆ ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! **Happy DeepLearning!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7e58EDipR1z"
      },
      "source": [
        "## ì™œ Deep Learning frameworksë¥¼ ì¨ì•¼í• ê¹Œìš”?\n",
        "\n",
        "* ìš°ë¦¬ì˜ Codeë¥¼ GPUë¡œ ì‹¤í–‰ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ë¥¼ í†µí•´ ëª¨ë¸ì„ í›¨ì”¬ ë¹ ë¥´ê²Œ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyTorchë‚˜ TensorFlowì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ CUDA ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•  í•„ìš” ì—†ì´(ì´ ê°•ì˜ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”) ìì‹ ë§Œì˜ ë§ì¶¤í˜• ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ìœ„í•´ GPUì˜ ì„±ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* ì´ ê°•ì˜ì—ì„œëŠ” í”„ë¡œì íŠ¸ì— ì´ëŸ¬í•œ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ (PyTorch)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ ì§ì ‘ ì‘ì„±í•  ë•Œë³´ë‹¤ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "* ê±°ì¸ë“¤ì˜ ì–´ê¹¨ ìœ„ì— ì„œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤! TensorFlowì™€ PyTorchëŠ” ëª¨ë‘ ì—¬ëŸ¬ë¶„ì˜ ì‚¶ì„ í›¨ì”¬ í¸í•˜ê²Œ ë§Œë“¤ì–´ì¤„ í›Œë¥­í•œ í”„ë ˆì„ì›Œí¬ì´ë©°, ì´ì œ ê·¸ ê¸°ëŠ¥ì„ ì´í•´í•˜ì…¨ìœ¼ë‹ˆ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì…”ë„ ë©ë‹ˆë‹¤ :)\n",
        "\n",
        "* ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ê³„ë‚˜ ì—…ê³„ì—ì„œ ì ‘í•  ìˆ˜ ìˆëŠ” ë”¥ ëŸ¬ë‹ ì½”ë“œì— ë…¸ì¶œë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\n",
        "\n",
        "## PyTorchë€ ë¬´ì—‡ì¼ê¹Œìš”?\n",
        "numpyì˜ ndarrayì™€ ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ëŠ” **Tensor objects**ì— ëŒ€í•´ì„œ ë™ì  computational graphsë¥¼ ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. PyTorchëŠ” ì‚¬ëŒì´ ì§ì ‘ backpropagationì„ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ì´ ê°•ë ¥í•œ **ìë™ ë¯¸ë¶„** ì—”ì§„ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì–´ë–»ê²Œ PyTorchë¥¼ ë°°ìš¸ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "ì´ ê³¼ì œë§Œìœ¼ë¡œëŠ” PyTorch ì „ë°˜ì„ ì´í•´í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ì¶”ì²œë˜ì§€ë§Œ, ë„ì›€ì´ ë  ë§Œí•œ ì‚¬ì´íŠ¸ì™€ í•™ìŠµ ë°©ë²•ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "PyTorch ê³µì‹ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ :\n",
        "https://tutorials.pytorch.kr/beginner/basics/intro.html\n",
        "\n",
        "Stanfordì˜ PyTorch ê°•ì˜ : https://github.com/jcjohnson/pytorch-examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQFg1RRpR11"
      },
      "source": [
        "# GPU\n",
        "`ëŸ°íƒ€ì„ -> ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½`ì„ í´ë¦­í•˜ê³  `í•˜ë“œì›¨ì–´ ê°€ì†ê¸°` ì•„ë˜ì—ì„œ `GPU`ë¥¼ ì„ íƒí•˜ë©´ Colabì—ì„œ GPU ì¥ì¹˜ë¡œ ìˆ˜ë™ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì „í™˜í•˜ë©´ ì»¤ë„ì´ ë‹¤ì‹œ ì‹œì‘ë˜ë¯€ë¡œ íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ì´ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cKvYIhDDpR12"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-bdb49170bb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gzip\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss.\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4q1RwwngAJz"
      },
      "source": [
        "`using device: cuda`ê°€ ë‚˜ì˜¤ë©´ ì„±ê³µì…ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swu-jxUigCVr"
      },
      "source": [
        "## What is 'CUDA'?\n",
        "\n",
        "\n",
        "> CUDA(\"Compute Unified Device Architecture\", ì¿ ë‹¤)ëŠ” ê·¸ë˜í”½ ì²˜ë¦¬ ì¥ì¹˜(GPU)ì—ì„œ ìˆ˜í–‰í•˜ëŠ” (ë³‘ë ¬ ì²˜ë¦¬) ì•Œê³ ë¦¬ì¦˜ì„ C í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ë¹„ë¡¯í•œ ì‚°ì—… í‘œì¤€ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” GPGPU ê¸°ìˆ ì´ë‹¤. -Wikipedia-\n",
        "\n",
        "GPUëŠ” ì›ë˜ ê·¸ ì´ë¦„ì—ì„œë„ ì•Œ ìˆ˜ ìˆë“¯ì´ Graphic ì—°ì‚°ì„ ìœ„í•œ ì¥ì¹˜ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPUê°€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ ì²˜ë¦¬í•œë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì—¬, ì¼ë°˜ì ì¸ matrix ì—°ì‚°ì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” GPGPU ê¸°ìˆ ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. NVIDAê°€ ì§€ì›í•˜ëŠ” CUDAë¥¼ í†µí•´ ê°œë°œìë“¤ì´ ì‰½ê²Œ GPU ìƒì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n",
        "\n",
        "ì§€ê¸ˆ ê³¼ì œëŠ” Colabì—ì„œ ì§„í–‰ë˜ë¯€ë¡œ íŠ¹ë³„íˆ CUDA Versionì„ ì„¤ì •í•´ ì¤„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ì•ìœ¼ë¡œ Local, ë˜ëŠ” Serverì—ì„œ Deep Learning ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë‹¤ ë³´ë©´ CUDA, PyTorch ë²„ì ¼ê³¼ ê´€ë ¨ëœ ì˜¤ë¥˜ë¥¼ ë§ì´ ë§ˆì£¼í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ´ ë• ë‹¤ìŒê³¼ ê°™ì€ ê¸°ìˆ ì„ ê²€í† í•´ ë³´ì„¸ìš”.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viZC941XecG6"
      },
      "source": [
        "# Google Mount\n",
        "\n",
        "* colabì— íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ëŠ” ê²½ìš° colab ëŸ°íƒ€ì„ì´ ëŠì–´ì ¸ë²„ë¦¬ê²Œ ë˜ë©´, ë‹¤ì‹œ íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì•¼ í•œë‹¤ëŠ” ë¶ˆìƒì‚¬ê°€ ìƒê¸°ê²Œ ë©ë‹ˆë‹¤.\n",
        "* colabì—ì„œëŠ” google driveì— ì ‘ê·¼í•˜ì—¬, google driveì— ì €ì¥ë˜ì–´ ìˆëŠ” ë°ì´í„°ì…‹ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* ì´ë²ˆ ê³¼ì œì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ì•ìœ¼ë¡œì˜ ê³¼ì œë¥¼ ìœ„í•˜ì—¬ ë¯¸ë¦¬ ì•Œì•„ë‘ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuMfr_caenVB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fI9EE0pR12"
      },
      "source": [
        "# Part I. ì¤€ë¹„\n",
        "ì´ì œ MNIST datasetì„ í™œìš©í•œ Classification ê³¼ì œë¥¼ ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤!\n",
        "\n",
        "ì¤€ë¹„ë‹¨ê³„ì—ì„œëŠ” í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , ì „ì²˜ë¦¬í•˜ëŠ” ë‹¨ê³„ê¹Œì§€ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmHmtOPfFpz"
      },
      "source": [
        "## MNIST Datasetì´ë€?\n",
        "\n",
        "* MNISTëŠ” ê°„ë‹¨í•œ ì»´í“¨í„° ë¹„ì „ ë°ì´í„° ì„¸íŠ¸ë¡œ, ì†ìœ¼ë¡œ ì“°ì—¬ì§„ ì´ë¯¸ì§€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "* ì¸ê³µì§€ëŠ¥ ì—°êµ¬ì˜ ê¶Œìœ„ì LeCunêµìˆ˜ê°€ ë§Œë“  ë°ì´í„° ì…‹ìœ¼ë¡œ, MNIST Datasetì„ í™œìš©í•œ ë¶„ë¥˜ ë¬¸ì œëŠ” ë”¥ëŸ¬ë‹ ìƒíƒœê³„ì˜ Hello, Worldê°™ì€ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "\n",
        "* MNISTëŠ” 60,000ê°œì˜ íŠ¸ë ˆì´ë‹ ì…‹ê³¼ 10,000ê°œì˜ í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆê³  ì´ì¤‘ íŠ¸ë ˆì´ë‹ ì…‹ì„ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê³  í…ŒìŠ¤íŠ¸ ì…‹ì„ ì‹ ê²½ë§ì„ ê²€ì¦í•˜ëŠ” ë°ì— ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "* ìˆ«ìëŠ” 0ì—ì„œ 9ê¹Œì§€ì˜ ê°’ì„ ê°€ì§€ë©°, ì´ë¯¸ì§€ì˜ í¬ê¸°ëŠ”(28x28 í”½ì…€)ë¡œ ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srBzs8OIfuFT"
      },
      "source": [
        "ì´ì œ ë°‘ì˜ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œì¼œ MNIST Datasetì„ colabì— ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjMM3t2QfRDy"
      },
      "outputs": [],
      "source": [
        "# colabì—ì„œëŠ” !{ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´}ë¥¼ í™œìš©í•˜ì—¬, ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY87MX0tgHiJ"
      },
      "source": [
        "## Dataset / DataLoader\n",
        "\n",
        "ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ë•Œ **Dataset**ê³¼ **DataLoader** í´ë˜ìŠ¤ë¥¼ ìì£¼ ì”ë‹ˆë‹¤.\n",
        "\n",
        "**Dataset**ì€ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì¶”ìƒ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— í•œ ë²ˆì— ëª¨ë‘ ë¡œë“œí•˜ì§€ ì•Šê³ , í•„ìš”í•œ ë¶€ë¶„ë§Œì„ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
        "Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì€ CustomDatasetì„ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´, `__len__`ê³¼ `__getitem__` ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë”©í•˜ì—¬ ë°ì´í„°ì˜ í¬ê¸°ì™€ ê° ìƒ˜í”Œì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì •ì˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "Dataset classë¥¼ í†µí•´ ë°ì´í„°ì…‹ì„ ì •ì˜í•˜ë©´, ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ í•„ìš”í•œ ì „ì²˜ë¦¬ ì‘ì—…ì„ í¬í•¨í•˜ì—¬ ë°ì´í„°ì— ì‰½ê²Œ ì ‘ê·¼í•˜ê³  ì¡°ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "DataLoaderëŠ” Dataset ê°ì²´ë¥¼ ê°ì‹¸ê³ , ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ê³µê¸‰í•  ìˆ˜ ìˆë„ë¡ í•´ì¤ë‹ˆë‹¤.\n",
        "ì´ëŠ” ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë§¤ìš° ìœ ìš©í•˜ë©°, í›ˆë ¨ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "DataLoaderëŠ” ë°ì´í„° ìƒ˜í”Œë§, ì…”í”Œë§, ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ì—¬ ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì—ì„œ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QqUsPYBgXz_"
      },
      "source": [
        "### ë¬¸ì œ 1\n",
        "\n",
        "ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ì›Œì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDBJu2TJpR13"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, istrain, trans = None, path = '/content/'):\n",
        "    '''\n",
        "      inputs:\n",
        "        - istrain : train modeì¸ì§€ í™•ì¸\n",
        "        - trans : ë°ì´í„° ì „ì²˜ë¦¬ ë° ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ í•¨ìˆ˜\n",
        "        - path : ë°ì´í„°ì…‹ì´ ì €ì¥ë˜ì–´ ìˆëŠ” í´ë” ê²½ë¡œ\n",
        "    '''\n",
        "    self.trans = trans\n",
        "\n",
        "    if istrain:\n",
        "      image_path = os.path.join(path, 'train-images-idx3-ubyte.gz')\n",
        "      label_path = os.path.join(path, 'train-labels-idx1-ubyte.gz')\n",
        "    else:\n",
        "      image_path = os.path.join(path, 't10k-images-idx3-ubyte.gz')\n",
        "      label_path = os.path.join(path, 't10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "    with gzip.open(image_path, 'rb') as f:\n",
        "      # self.imagesëŠ” ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë‹´ê³  ìˆëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.\n",
        "      self.images = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "      self.images = self.images.reshape(-1, 1, 28, 28)\n",
        "\n",
        "    with gzip.open(label_path, 'rb') as f:\n",
        "      # self.labelsëŠ” ëª¨ë“  ë¼ë²¨ì„ ë‹´ê³  ìˆëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.\n",
        "      self.labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    ###########################################################################\n",
        "    # __len__(self) í•¨ìˆ˜ëŠ” ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.               #\n",
        "    # self.imagesë‚˜ self.labelsë¥¼ í™œìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”. #\n",
        "    ###########################################################################\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    ###########################################################################\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ###########################################################################\n",
        "    # __getitem__(self, idx) í•¨ìˆ˜ëŠ” idxë²ˆì§¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.     #\n",
        "    # self.imagesì™€ self.labelsë¥¼ í™œìš©í•˜ì—¬ idxë²ˆì§¸ imageì™€ labelì„ ë°˜í™˜í•˜ì„¸ìš”.#\n",
        "    ###########################################################################\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    ###########################################################################\n",
        "    if self.trans:\n",
        "      image = self.trans(image)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvkrWW0Njkod"
      },
      "outputs": [],
      "source": [
        "# ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë°”ê¾¸ê³ , ì ë‹¹í•œ ê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸° ìœ„í•´ í•„ìš”í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "transform = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HcZP0htjnqp"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(trans = transform, istrain = True)\n",
        "test_dataset = CustomDataset(trans = transform, istrain = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932U6Ek4jrdD"
      },
      "source": [
        "ë°ì´í„°ì…‹ì˜ ê°œìˆ˜ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3biIHQSjqqb"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of train dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of test dataset: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkku-EHujvyc"
      },
      "source": [
        "### ë¬¸ì œ 2\n",
        "\n",
        "* ë”¥ëŸ¬ë‹ ë°ì´í„°ì—ì„œëŠ” train, test datasetì´ì™¸ì—ë„ validation datasetì´ë¼ëŠ” ê²ƒì´ ìˆìŠµë‹ˆë‹¤. (ê°•ì˜ ìë£Œ ì°¸ê³ )\n",
        "\n",
        "* validation datasetì´ ì§ì ‘ì ìœ¼ë¡œ ì£¼ì–´ì§€ì§€ ì•Šìœ¼ë©´, ë³´í†µ train datasetì—ì„œ ì¼ë¶€ë¥¼ ë–¼ì–´ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "* pytorchì—ì„œ ì œê³µí•˜ëŠ” `random_split`ì´ë¼ëŠ” í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬, ì§ì ‘ train datasetê³¼ validation datasetì„ 8:2 ë¹„ìœ¨ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”!\n",
        "\n",
        "* `random_split` Documentation : https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En3XCG31jvA7"
      },
      "outputs": [],
      "source": [
        "train_size = # FILL YOUR CODE HERE\n",
        "val_size = # FILL YOUR CODE HERE\n",
        "train_dataset, val_dataset = # FILL YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPNLemoplxV6"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of train dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of valid dataset: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ZoDnoLlz6W"
      },
      "source": [
        "### ë¬¸ì œ 3\n",
        "\n",
        "* `DataLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ batch ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
        "* ë¹„ì–´ìˆëŠ” ë¶€ë¶„ì„ ì±„ì›Œì£¼ì„¸ìš”!\n",
        "* `DataLoader` Documentation : https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B70XE6ZPmTYZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "train dataloaderëŠ” batch sizeê°€ 64ì´ë©°, ë°ì´í„°ì…‹ì´ ëœë¤ìœ¼ë¡œ ì„ì—¬ ë°˜í™˜ë©ë‹ˆë‹¤.\n",
        "val dataloaderì™€ test dataloaderëŠ” batch sizeê°€ 32ì´ë©°, ë°ì´í„°ì…‹ì´ ì„ì´ì§€ ì•Šê³  ë°˜í™˜ë©ë‹ˆë‹¤.\n",
        "'''\n",
        "train_dataloader = # FILL YOUR CODE HERE\n",
        "val_dataloader = # FILL YOUR CODE HERE\n",
        "test_dataloader = # FILL YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCsAL5_VmyUI"
      },
      "source": [
        "### ë¬¸ì œ 4, 5\n",
        "\n",
        "* ë‹¤ìŒ ì½”ë“œë“¤ì„ ì‹¤í–‰í•˜ê³ , ìì‹ ì˜ ìƒê°ì„ ì ëŠ” ë€ì— ììœ ë¡­ê²Œ ìì‹ ì˜ ìƒê°ì„ ì ì–´ì£¼ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLhJa12PnK11"
      },
      "source": [
        "---\n",
        "MNIST Datasetì˜ imageë¥¼ label ë³„ë¡œ ì¶œë ¥í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3NTfzq8m9d8"
      },
      "outputs": [],
      "source": [
        "def get_samples_per_class(images, labels):\n",
        "    samples = {}\n",
        "    for img, lbl in zip(images, labels):\n",
        "        if lbl not in samples:\n",
        "            samples[lbl] = img\n",
        "        if len(samples) == 10:\n",
        "            break\n",
        "    return samples\n",
        "\n",
        "tmp_dataset = CustomDataset(istrain = True)\n",
        "samples = get_samples_per_class(tmp_dataset.images, tmp_dataset.labels)\n",
        "\n",
        "sorted_samples = sorted(samples.items())\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(7, 3))\n",
        "for i, (label, image) in enumerate(sorted_samples):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    ax.imshow(image.squeeze(), cmap='gray')\n",
        "    ax.set_title(f'Label: {label}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmjXkJjSnY6g"
      },
      "source": [
        "MNIST Datasetì˜ labelë³„ ë¶„í¬ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo1BpEnCnd2w"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(tmp_dataset.labels, return_counts=True)\n",
        "label_distribution = dict(zip(unique, counts))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(label_distribution.keys(), label_distribution.values(), color='blue')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Label Distribution in MNIST Training Set')\n",
        "plt.xticks(np.arange(10))\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxH646donied"
      },
      "source": [
        "**ë¬¸ì œ 4**\n",
        "\n",
        "ë‹¤ìŒ ë¶„í¬ëŠ” ëª¨ë¸ì´ ìˆ«ìë¥¼ ì¸ì‹í•˜ëŠ” ë°ì— ìˆì–´ ì í•©í•œ í•™ìŠµ ë°ì´í„°ì…‹ì˜ ë¶„í¬ì¼ê¹Œìš”?\n",
        "ì´ìœ ì™€ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "* ë‹µ :\n",
        "* ì´ìœ  :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFIwxejenvlA"
      },
      "source": [
        "MNIST Datasetì˜ labelë³„ í‰ê·  ì´ë¯¸ì§€ì˜ ëª¨ìŠµì„ ì¶œë ¥í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3i3T7non10O"
      },
      "outputs": [],
      "source": [
        "mean_images = {}\n",
        "for label in range(10):\n",
        "    mean_images[label] = tmp_dataset.images[tmp_dataset.labels == label].mean(axis=0)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "for i, (label, mean_image) in enumerate(mean_images.items()):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    ax.imshow(mean_image.squeeze(), cmap='gray')\n",
        "    ax.set_title(f'Label: {label}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv78Zc51n6Up"
      },
      "source": [
        "Randomìœ¼ë¡œ 2000ê°œì˜ imageë¥¼ ë¶ˆëŸ¬ì™€ì„œ image featureì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ì—¬ 2ì°¨ì› í‰ë©´ì— ë‚˜íƒ€ë‚¸ ê²°ê³¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE_UKjZPn5XU"
      },
      "outputs": [],
      "source": [
        "n_samples = 2000\n",
        "indices = np.random.choice(len(tmp_dataset.images), n_samples, replace=False)\n",
        "images_subset = tmp_dataset.images[indices].reshape(n_samples, -1)\n",
        "labels_subset = tmp_dataset.labels[indices]\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(images_subset)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for label in np.unique(labels_subset):\n",
        "    indices = labels_subset == label\n",
        "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE projection of MNIST dataset')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h9Dmmq-oKd_"
      },
      "source": [
        "**ë¬¸ì œ 5**\n",
        "\n",
        "ì‹¤í–‰ ê²°ê³¼ë¥¼ í†µí•´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì•Œ ìˆ˜ ìˆëŠ” ì ì„ 2ê°€ì§€ ì´ìƒ ì ì–´ì£¼ì„¸ìš”.\n",
        "\n",
        "1.  \n",
        "2.   \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg86udhQpmRE"
      },
      "source": [
        "# Part II. BackPropagation ì´í•´í•˜ê¸°\n",
        "\n",
        "ë”¥ëŸ¬ë‹ì—ì„œëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ BackPropagation ì´ë¼ëŠ” ê²ƒì„ í™œìš©í•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì˜ í•™ìŠµì— êµ‰ì¥íˆ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ê²ƒì¸ ë§Œí¼, í¸ë¯¸ë¶„, Chain Ruleì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ê³¼ ì¼ë¶€ í•¨ìˆ˜ë¥¼ ì§ì ‘ êµ¬í˜„í•´ë³´ëŠ” ê¸°íšŒë¥¼ ê°€ì ¸ë³´ê³ ì í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3YssC4pqNA0"
      },
      "source": [
        "## í¸ë¯¸ë¶„\n",
        "\n",
        "* ì‹¤ì œ ë”¥ëŸ¬ë‹ì—ì„œëŠ” í•˜ë‚˜ì˜ ë³€ìˆ˜ë§Œì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ 2ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, í¸ë¯¸ë¶„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "* í¸ë¯¸ë¶„ì€ $d$ ëŒ€ì‹  $\\partial$ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ë©°, ë³€ìˆ˜ê°€ 2ê°œ ì´ìƒì„ì— ìœ ì˜í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
        "* $x_0$ì™€ $x_1$ì´ ë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, $\\frac{\\partial f(x_0, x_1)}{\\partial x_0}$ëŠ” $x_0$ë¥¼ ë³€ìˆ˜ë¡œ ë³´ê³ , ë‚˜ë¨¸ì§€ ë³€ìˆ˜ë“¤ì€ ëª¨ë‘ ìƒìˆ˜ë¡œ ë³¸ ì±„ ë¯¸ë¶„ì„ í•œë‹¤ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "* Example\n",
        "\n",
        "\\begin{align}\n",
        "  f(x_0, x_1) = x_0^2 + x_1^2 + x_0x_1 \\\\\n",
        "  \\\\\n",
        "  \\frac{\\partial f(x_0, x_1)}{\\partial x_0} = 2x_0 + x_1\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqPUvqU-qy9q"
      },
      "outputs": [],
      "source": [
        "def numerical_diff(f, x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "\n",
        "  for idx in range(x.size):\n",
        "      tmp_val = x[idx]\n",
        "      x[idx] = tmp_val + h\n",
        "      fxh1 = f(x)\n",
        "\n",
        "      x[idx] = tmp_val - h\n",
        "      fxh2 = f(x)\n",
        "\n",
        "      grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "      x[idx] = tmp_val\n",
        "\n",
        "\n",
        "  return grad\n",
        "\n",
        "def function(x):\n",
        "  return x[0]**2 + x[1]**2 + x[0]*x[1]\n",
        "\n",
        "x = np.array([4., 5.])\n",
        "numerical_diff(function, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Na9WUj8rMO6"
      },
      "source": [
        "## Chain rule\n",
        "\n",
        "ë”¥ëŸ¬ë‹ì—ì„œ ì—°ì‡„ ë²•ì¹™(Chain Rule)ì€ ì—­ì „íŒŒ(backpropagation)ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì€ ì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë©°, ì¶œë ¥ ì¸µì—ì„œ ì…ë ¥ ì¸µìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ì „íŒŒí•˜ë©´ì„œ ê° ì¸µì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. í•©ì„± í•¨ìˆ˜ $f(g(x))$ì— ëŒ€í•´ ì—°ì‡„ ë²•ì¹™ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ë©ë‹ˆë‹¤.\n",
        "\n",
        "\\begin{align}\n",
        "  \\frac{d}{dx}f(g(x))\n",
        "  = \\frac{dg(x)}{dx} \\cdot \\frac{df(g(x))}{dg(x)}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "ì´ëŠ” ì†ì‹¤ í•¨ìˆ˜ì˜ ì…ë ¥ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê° ì¸µì˜ ê¸°ìš¸ê¸°ë¥¼ ê³±í•˜ì—¬ ê³„ì‚°í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œëŠ” ì—°ì‡„ ë²•ì¹™ì„ ì ìš©í•œ ê²½ìš°ì™€ ì ìš©í•˜ì§€ ì•Šì€ ê²½ìš°ì˜ ë¯¸ë¶„ì„ ë¹„êµí•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq3P-0INrglG"
      },
      "outputs": [],
      "source": [
        "def g(x):\n",
        "    return x**2\n",
        "\n",
        "def f(u):\n",
        "    return np.sin(u)\n",
        "\n",
        "def composite_function(x):\n",
        "    return f(g(x))\n",
        "\n",
        "def chain_rule_derivative(x):\n",
        "    u = g(x)\n",
        "    df_du = numerical_diff(f, u)\n",
        "    du_dx = numerical_diff(g, x)\n",
        "    return du_dx * df_du\n",
        "\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4\n",
        "    return (f(x + h) - f(x - h)) / (2 * h)\n",
        "\n",
        "x = np.array([2.0])\n",
        "chain_rule_result = chain_rule_derivative(x)\n",
        "numerical_result = numerical_diff(composite_function, x)\n",
        "\n",
        "print(f\"result of chain rule derivative : {chain_rule_result}\")\n",
        "print(f\"result of numerical differentiation : {numerical_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KW9hGALuXCZ"
      },
      "source": [
        "## ë°‘ë°”ë‹¥ë¶€í„° êµ¬í˜„í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLO6iHpBpR15"
      },
      "source": [
        "### Flatten\n",
        "PyTorch TensorsëŠ” ê°œë…ì ìœ¼ë¡œ nì°¨ì› ë°°ì—´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. nì°¨ì› ìˆ«ì ê·¸ë¦¬ë“œì´ë©°, PyTorchëŠ” nì°¨ì› ë°°ì—´ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ í…ì„œì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆëŠ” ë§ì€ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¡œ, ì•„ë˜ì—ì„œëŠ” ì™„ì „íˆ ì—°ê²°ëœ ì‹ ê²½ë§ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” `flatten` í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ N x C x H x W í˜•íƒœì˜ í…ì„œì— ì €ì¥ëœë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”:\n",
        "\n",
        "* Nì€ ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜ì…ë‹ˆë‹¤.\n",
        "* CëŠ” ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤.\n",
        "* HëŠ” ì¤‘ê°„ íŠ¹ì§• ë§µì˜ í”½ì…€ ë‹¨ìœ„ ë†’ì´ì…ë‹ˆë‹¤.\n",
        "* WëŠ” ì¤‘ê°„ í”¼ì²˜ ë§µì˜ ë†’ì´(í”½ì…€)ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ëŠ” 2D convolution ê°™ì´ ì¤‘ê°„ íŠ¹ì§•ì´ ì„œë¡œ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì— ëŒ€í•œ ê³µê°„ì  ì´í•´ê°€ í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì í•©í•œ ë°©ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ fully connected affine layersë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‹¨ì¼ ë²¡í„°ë¡œ í‘œí˜„í•´ì•¼ í•˜ë¯€ë¡œ ë°ì´í„°ì˜ ì—¬ëŸ¬ ì±„ë„, í–‰, ì—´ì„ ë¶„ë¦¬í•˜ëŠ” ê²ƒì€ ë” ì´ìƒ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ 'flatten' ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ë‹¹ `C x H x W` ê°’ì„ í•˜ë‚˜ì˜ ê¸´ ë²¡í„°ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. ì•„ë˜ì˜ flatten í•¨ìˆ˜ëŠ” ë¨¼ì € ì£¼ì–´ì§„ ë°ì´í„° ë°°ì¹˜ì—ì„œ N, C, H, W ê°’ì„ ì½ì€ ë‹¤ìŒ í•´ë‹¹ ë°ì´í„°ì˜ 'view'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. \"view\"ëŠ” numpyì˜ \"reshape\" ë©”ì„œë“œì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. xì˜ ì°¨ì›ì„ N x ?? ë¡œ ì¬í˜•ì„±í•˜ë©°, ì—¬ê¸°ì„œ ?? ëŠ” ë¬´ì—‡ì´ë“  í—ˆìš©ë©ë‹ˆë‹¤(ì´ ê²½ìš° C x H x Wê°€ ë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUnA0EncpR15"
      },
      "outputs": [],
      "source": [
        "def flatten(x):\n",
        "    N = x.shape[0]\n",
        "    return x.view(N, -1)\n",
        "\n",
        "def test_flatten():\n",
        "    x = torch.arange(12).view(2, 1, 3, 2)\n",
        "    print('Before flattening: ', x)\n",
        "    print('After flattening: ', flatten(x))\n",
        "\n",
        "test_flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEL8vbVfu7rJ"
      },
      "source": [
        "### Sigmoid\n",
        "\n",
        "SigmoidëŠ” Gradient Vanishing ë¬¸ì œ ë•Œë¬¸ì— ë”¥ëŸ¬ë‹ì—ì„œ ë§ì´ í™œìš©ë˜ì§€ ëª»í•˜ê³  ìˆì§€ë§Œ, ë‹¨ìˆœí•œ taskì—ì„œëŠ” ì•„ì§ê¹Œì§€ ì“°ì´ê³  ìˆìŠµë‹ˆë‹¤. Sigmoid í•¨ìˆ˜ì˜ forward ë° backward ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. (backwardëŠ” ì§ì ‘ ë¯¸ë¶„í•˜ë©´ì„œ ì¦ëª…í•´ë³´ì„¸ìš”!)\n",
        "\n",
        "**forward**\n",
        "\n",
        "\\begin{align}\n",
        "  y = \\sigma(x) = \\frac{1}{1 + \\mbox{exp}(-x)}\n",
        "\\end{align}\n",
        "\n",
        "**backward**\n",
        "\\begin{align}\n",
        "  \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} = dout \\cdot \\sigma(x) \\cdot (1 - \\sigma(x))\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik9TqnnuvEPM"
      },
      "outputs": [],
      "source": [
        "class Sigmoid():\n",
        "  def __init__(self):\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = 1 / (1+torch.exp(-x))\n",
        "    self.y = y\n",
        "    return y\n",
        "\n",
        "  def backward(self, dout):\n",
        "    return dout * (1-self.y) * self.y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsVplnGJuhDY"
      },
      "source": [
        "### ë¬¸ì œ 6. ReLU\n",
        "\n",
        "ReLUëŠ” ë”¥ëŸ¬ë‹ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” í™œì„±í™” í•¨ìˆ˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ReLUì˜ forwardì™€ backward ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**forward**\n",
        "\\begin{align}\n",
        "  y =\n",
        "  \\begin{cases}\n",
        "    0, & x \\leq 0\\\\\n",
        "    x, & x > 0\n",
        "  \\end{cases}\n",
        "\\end{align}\n",
        "\n",
        "\\\\\n",
        "\n",
        "**backward**\n",
        "\\begin{align}\n",
        "  \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} =\n",
        "  \\begin{cases}\n",
        "    0, & x \\leq 0\\\\\n",
        "    dout, & x > 0\n",
        "  \\end{cases}\n",
        "\\end{align}\n",
        "\n",
        "\\\\\n",
        "\n",
        "Sigmoid ì˜ˆì‹œë¥¼ ë³´ê³ , ReLUì˜ forward, backward ë¹ˆì¹¸ì„ ì±„ì›Œì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IT6ovE0uzvu"
      },
      "outputs": [],
      "source": [
        "class ReLU():\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1mxlj_IvGf1"
      },
      "source": [
        "### ë¬¸ì œ 7. Linear\n",
        "\n",
        "`Linear`ëŠ” PyTorchì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë ˆì´ì–´ë¡œ, ì…ë ¥ ë°ì´í„°ë¥¼ ì„ í˜• ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì„ í˜• ë³€í™˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤:\n",
        "\n",
        "**forward**\n",
        "\\begin{align}\n",
        "\\mathbf{y} = \\mathbf{x}W + \\mathbf{b}\n",
        "\\end{align}\n",
        "\n",
        "**backward**\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial W} = x^T \\cdot dout \\\\\n",
        "\\\\\n",
        "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial b} = \\sum_{i=1}^{N} dout_i \\\\\n",
        "\\\\\n",
        "\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} = dout \\cdot W^T\n",
        "\\end{align}\n",
        "\n",
        "ì—¬ê¸°ì„œ xëŠ” ì…ë ¥ ë²¡í„°, WëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬, bëŠ” í¸í–¥ ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uJtgN5QvLbC"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    self.W = np.random.randn(input_dim, output_dim) * 0.01\n",
        "    self.b = np.zeros(output_dim)\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHNc34Au-EI0"
      },
      "source": [
        "### ë¬¸ì œ 8. CrossEntropyLoss\n",
        "\n",
        "êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì€ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ íƒ€ê²Ÿ ë¶„í¬ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "**Softmax Function**\n",
        "\n",
        "* ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ ë¡œì§“ ê°’ì„ í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê° ì…ë ¥ ê°’ì˜ ì§€ìˆ˜ í•¨ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„, ì´ ê°’ë“¤ì˜ í•©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "\\begin{align}\n",
        "\t\\mbox{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}} = \\frac{e^{(z_i - c)}}{\\sum_{j} e^{(z_j - c)}}\n",
        "\\end{align}\n",
        "\n",
        "* ì—¬ê¸°ì„œ $z_i$ëŠ” ì…ë ¥ ë²¡í„°ì˜ ië²ˆì§¸ ì›ì†Œì…ë‹ˆë‹¤. ê° ì›ì†Œì˜ ì§€ìˆ˜ ê°’ì„ ê³„ì‚°í•œ í›„ ì´ ì§€ìˆ˜ ê°’ë“¤ì˜ í•©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° ì›ì†Œë¥¼ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "**Cross Entropy Calculation - forward**\n",
        "* êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì€ ì˜ˆì¸¡ëœ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ íƒ€ê²Ÿ ë¶„í¬ ê°„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì‹¤ì œ íƒ€ê²Ÿ ê°’ì˜ ì›-í•« ì¸ì½”ë”© ë²¡í„°ì™€ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì¶œë ¥ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "\\begin{align}\n",
        "L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} \\log(\\hat{y}_{ic})\n",
        "\\end{align}\n",
        "\n",
        "* ì—¬ê¸°ì„œ:\n",
        "  * $N$ì€ ë°°ì¹˜ í¬ê¸°\n",
        "  * $C$ëŠ” í´ë˜ìŠ¤ì˜ ìˆ˜\n",
        "  * $y_{ic}$ëŠ” ië²ˆì§¸ ìƒ˜í”Œì˜ ì‹¤ì œ í´ë˜ìŠ¤ì˜ ì›-í•« ì¸ì½”ë”© ê°’\n",
        "  * $\\hat{y}_{ic}$ëŠ” ië²ˆì§¸ ìƒ˜í”Œì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì¶œë ¥ ê°’\n",
        "\n",
        "**backward**\n",
        "* ì—­ì „íŒŒë¥¼ í†µí•´ ì†ì‹¤ í•¨ìˆ˜ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê° ë¡œì§“ ê°’ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial z_{i}} = \\frac{1}{N} (\\hat{y}_{i} - y_{i})\n",
        "\\end{align}\n",
        "\n",
        "* ì—¬ê¸°ì„œ:\n",
        "  * $\\hat{y}_{i}$ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ ì¶œë ¥ ê°’\n",
        "  * $y_{i}$ëŠ” ì‹¤ì œ íƒ€ê²Ÿ ê°’\n",
        "\n",
        "* ì´ ìˆ˜ì‹ì„ í†µí•´ ê° ë¡œì§“ ê°’ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ì—¬ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boYn8sFt-C1a"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss:\n",
        "    def __init__(self):\n",
        "        self.softmax_value = None\n",
        "        self.pred = None\n",
        "        self.target = None\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def to_one_hot(self, y, batch_size, num_classes):\n",
        "        one_hot = np.zeros((batch_size, num_classes))\n",
        "        one_hot[np.arange(batch_size), y] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        \"\"\"\n",
        "        CrossEntropyLossì˜ forward íŒ¨ìŠ¤.\n",
        "\n",
        "        Inputs:\n",
        "          - pred (numpy.ndarray): ì˜ˆì¸¡í•œ ë¡œì§“ ê°’.\n",
        "          - target (numpy.ndarray): ì‹¤ì œ íƒ€ê²Ÿ ê°’ (ì›-í•« ì¸ì½”ë”© í˜•ì‹).\n",
        "\n",
        "        Returns:\n",
        "          - loss: ë°°ì¹˜ì— ëŒ€í•œ í‰ê·  êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤.\n",
        "        \"\"\"\n",
        "        batch_size, num_classes = pred.shape\n",
        "\n",
        "        self.pred = pred\n",
        "        self.target = self.to_one_hot(target, batch_size, num_classes)\n",
        "\n",
        "        # FILL YOUR CODE HERE\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout):\n",
        "        \"\"\"\n",
        "        CrossEntropyLossì˜ backward íŒ¨ìŠ¤.\n",
        "\n",
        "        Inputs:\n",
        "          - dout : 1\n",
        "\n",
        "        Returns:\n",
        "          - grad: ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸.\n",
        "        \"\"\"\n",
        "        # FILL YOUR CODE HERE\n",
        "\n",
        "        return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgkUWAzazIb3"
      },
      "source": [
        "### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8esChpeqzFEj"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "  def __init__(self, learning_rate):\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def step(self, params, grads):\n",
        "    for key in params.keys():\n",
        "      params[key] -= self.learning_rate * grads[key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISnEux55zXgQ"
      },
      "source": [
        "### ë¬¸ì œ 9. ì „ì²´ í•™ìŠµ ì½”ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIVcuPCEzkML"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class ThreeLayerNet:\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dims, output_dim):\n",
        "    self.params = {}\n",
        "    self.layers = OrderedDict()\n",
        "\n",
        "    self.layers['fc1'] = Linear(input_dim, hidden_dims[0])\n",
        "    self.layers['relu1'] = ReLU()\n",
        "    self.layers['fc2'] = Linear(hidden_dims[0], hidden_dims[1])\n",
        "    self.layers['relu2'] = ReLU()\n",
        "    self.layers['fc3'] = Linear(hidden_dims[1], output_dim)\n",
        "\n",
        "    self.params['W1'] = self.layers['fc1'].W\n",
        "    self.params['b1'] = self.layers['fc1'].b\n",
        "    self.params['W2'] = self.layers['fc2'].W\n",
        "    self.params['b2'] = self.layers['fc2'].b\n",
        "    self.params['W3'] = self.layers['fc3'].W\n",
        "    self.params['b3'] = self.layers['fc3'].b\n",
        "\n",
        "    self.last_layer = CrossEntropyLoss()\n",
        "\n",
        "  def predict(self, x):\n",
        "    '''\n",
        "    flattenì„ ì‚¬ìš©í•˜ì—¬ tensorë¥¼ 2ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ê³ , self.layersì— ìˆëŠ” layerë“¤ì„ ì‚¬ìš©í•˜ì—¬, outputì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”!\n",
        "    '''\n",
        "\n",
        "    # FILL YOUR CODE HERE\n",
        "\n",
        "    return out\n",
        "\n",
        "  def loss(self, y, t):\n",
        "    return self.last_layer.forward(y, t)\n",
        "\n",
        "  def accuracy(self, y, t):\n",
        "    y = np.argmax(y, axis = 1)\n",
        "    accuracy = np.sum(y == t) / float(t.shape[0])\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "  def gradient(self):\n",
        "\n",
        "    dout = 1\n",
        "    dout = self.last_layer.backward(dout)\n",
        "\n",
        "    layers = list(self.layers.values())\n",
        "    layers.reverse()\n",
        "    for layer in layers:\n",
        "      dout = layer.backward(dout)\n",
        "\n",
        "    grads = {}\n",
        "\n",
        "\n",
        "    grads['W1'] = self.layers['fc1'].dW\n",
        "\n",
        "    '''\n",
        "    ìœ„ì˜ ì˜ˆì‹œì²˜ëŸ¼ gradsì— ê°ê°ì˜ parameterì˜ gradientê°’ì„ dictionary í˜•íƒœë¡œ ì €ì¥í•´ì£¼ì„¸ìš”.\n",
        "    '''\n",
        "\n",
        "    # FILL YOUR CODE HERE\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8OmtcKf6qbN"
      },
      "outputs": [],
      "source": [
        "optimizer = SGD(learning_rate = 0.0001)\n",
        "model = ThreeLayerNet(input_dim = 784, hidden_dims = [256, 64], output_dim=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_x3oDuva7Jgi",
        "outputId": "50bb186e-63b2-4c3b-8780-bd90be19b440"
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):\n",
        "  for idx, data in enumerate(tqdm(train_dataloader)):\n",
        "    images, labels = data\n",
        "    labels = labels.numpy()\n",
        "\n",
        "    output = model.predict(images)\n",
        "    loss = model.loss(output, labels)\n",
        "    grads = model.gradient()\n",
        "    optimizer.step(model.params, grads)\n",
        "    train_acc = model.accuracy(output, labels)\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"[Model 1] Epoch: {} Train Loss: {:.4f} Train Accuracy: {:.4f}\".format(epoch+1, loss, train_acc))\n",
        "\n",
        "  for data in tqdm(val_dataloader):\n",
        "    images, labels = data\n",
        "    labels = labels.numpy()\n",
        "    output = model.predict(images)\n",
        "    val_acc = model.accuracy(output, labels)\n",
        "\n",
        "  print(\"[Model 1] Epoch: {} Valid Accuracy: {:.4f}\".format(epoch+1, val_acc))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVAtckopR14"
      },
      "source": [
        "# Part III. Barebones PyTorch\n",
        "PyTorchëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ í¸ë¦¬í•˜ê²Œ ì •ì˜í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•˜ì´ë ˆë²¨ APIì™€ í•¨ê»˜ ì œê³µë˜ë©°, ì´ íŠœí† ë¦¬ì–¼ì˜ Part IVì—ì„œëŠ” ì´ë¥¼ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” autograd engineì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ Barebones PyTorch ìš”ì†Œë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ ì—°ìŠµì„ ë§ˆì¹˜ë©´ í•˜ì´ë ˆë²¨ ëª¨ë¸ APIë¥¼ ë” ì˜ ì´í•´í•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‘ ê°œì˜ ìˆ¨ê²¨ì§„ ë ˆì´ì–´ê°€ ìˆê³  MNIST ë¶„ë¥˜ë¥¼ ìœ„í•œ biasê°€ ì—†ëŠ” ê°„ë‹¨í•œ Fully-connected ReLU ë„¤íŠ¸ì›Œí¬ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ êµ¬í˜„ì€ PyTorch í…ì„œì—ì„œ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ forward passë¥¼ ê³„ì‚°í•˜ê³  PyTorch autogradë¥¼ ì‚¬ìš©í•˜ì—¬ gradientë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ì˜ˆì œ ì´í›„ì— ë” ì–´ë ¤ìš´ ë²„ì „ì„ ì‘ì„±í•  ê²ƒì´ë¯€ë¡œ ëª¨ë“  ì¤„ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "`requires_grad = True`ë¡œ PyTorch í…ì„œë¥¼ ìƒì„±í•˜ë©´ í•´ë‹¹ í…ì„œë¥¼ í¬í•¨í•˜ëŠ” ì—°ì‚°ì€ ê°’ë§Œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì‚° ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ê·¸ë˜í”„ë¥¼ í†µí•´ ì‰½ê²Œ ì—­ì „íŒŒí•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì†ì‹¤ì— ëŒ€í•œ ì¼ë¶€ í…ì„œì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ xê°€ `x.requires_grad == True`ì¸ í…ì„œì¸ ê²½ìš°, ì—­ì „íŒŒ í›„ `x.grad`ëŠ” ë§ˆì§€ë§‰ì— scalar lossì— ëŒ€í•œ xì˜ ê¸°ìš¸ê¸°ë¥¼ ë³´ìœ í•˜ëŠ” ë˜ ë‹¤ë¥¸ í…ì„œê°€ ë  ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnPI6lVpR16"
      },
      "source": [
        "### ë¬¸ì œ 10 : Barebones PyTorch: Two-Layer Network\n",
        "\n",
        "ì—¬ê¸°ì—ì„œëŠ” ì´ë¯¸ì§€ ë°ì´í„° ë°°ì¹˜ì— ëŒ€í•´ ì™„ì „íˆ ì—°ê²°ëœ 2ê³„ì¸µ ReLU ë„¤íŠ¸ì›Œí¬ì˜ í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ `two_layer_fc`ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ 0ì„ ì‹¤í–‰í•˜ì—¬ ì¶©ëŒì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ì§€, ì˜¬ë°”ë¥¸ ëª¨ì–‘ì˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‘ì„±í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ êµ¬í˜„ì„ ì½ê³  ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg43S8B0pR16"
      },
      "outputs": [],
      "source": [
        "def two_layer_fc(x, params):\n",
        "    \"\"\"\n",
        "    A fully-connected neural networks; the architecture is:\n",
        "    NN is fully connected -> ReLU -> fully connected layer.\n",
        "    Note that this function only defines the forward pass;\n",
        "    PyTorch will take care of the backward pass for us.\n",
        "\n",
        "    The input to the network will be a minibatch of data, of shape\n",
        "    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
        "    and the output layer will produce scores for C classes.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
        "      input data.\n",
        "    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
        "      w1 has shape (D, H) and w2 has shape (H, C).\n",
        "\n",
        "    Returns:\n",
        "    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
        "      the input data x.\n",
        "    \"\"\"\n",
        "    # first we flatten the image\n",
        "    x = flatten(x)  # shape: [batch_size, C x H x W]\n",
        "\n",
        "    w1, w2 = params\n",
        "\n",
        "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
        "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
        "    # PyTorch to build a computational graph, allowing automatic computation of\n",
        "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
        "    # don't need to keep references to intermediate values.\n",
        "    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n",
        "\n",
        "    ################################################################################\n",
        "    # TODO: get model socres using w1, w2 and x                                    #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ################################################################################\n",
        "    #                                 END OF YOUR CODE                             #\n",
        "    ################################################################################\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def two_layer_fc_test():\n",
        "    hidden_layer_size = 42\n",
        "    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
        "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n",
        "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n",
        "    scores = two_layer_fc(x, [w1, w2])\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "\n",
        "two_layer_fc_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jxzynJspR19"
      },
      "source": [
        "### Barebones PyTorch: Initialization\n",
        "ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•˜ëŠ” ëª‡ ê°€ì§€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ì‘ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- `random_weight(shape)`ëŠ” Kaiming normalization ë°©ë²•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "- `zero_weight(shape)`ëŠ” ëª¨ë“  0ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë°”ì´ì–´ìŠ¤ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "`random_weight` í•¨ìˆ˜ëŠ” Kaiming normal initialization ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
        "\n",
        "He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXkgnTzMpR19"
      },
      "outputs": [],
      "source": [
        "def random_weight(shape):\n",
        "    \"\"\"\n",
        "    Create random Tensors for weights; setting requires_grad=True means that we\n",
        "    want to compute gradients for these Tensors during the backward pass.\n",
        "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
        "    \"\"\"\n",
        "    if len(shape) == 2:  # FC weight\n",
        "        fan_in = shape[0]\n",
        "    else:\n",
        "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
        "    # randn is standard normal distribution generator.\n",
        "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
        "    w.requires_grad = True\n",
        "    return w\n",
        "\n",
        "def zero_weight(shape):\n",
        "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# create a weight of shape [3 x 5]\n",
        "# you should see the type `torch.cuda.FloatTensor` if you use GPU.\n",
        "# Otherwise it should be `torch.FloatTensor`\n",
        "random_weight((3, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z1t3y6YpR19"
      },
      "source": [
        "### Barebones PyTorch: Check Accuracy\n",
        "ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë˜ëŠ” ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì •í™•ë„ë¥¼ í™•ì¸í•  ë•Œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ PyTorchê°€ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ë§Œë“¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ê°€ ìƒì„±ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ `torch.no_grad()` context managerì—ì„œ ê³„ì‚° ë²”ìœ„ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jre5tpX2pR1-"
      },
      "outputs": [],
      "source": [
        "def check_accuracy_part2(loader, model_fn, params, istrain = True):\n",
        "    \"\"\"\n",
        "    Check the accuracy of a classification model.\n",
        "\n",
        "    Inputs:\n",
        "    - loader: A DataLoader for the data split we want to check\n",
        "    - model_fn: A function that performs the forward pass of the model,\n",
        "      with the signature scores = model_fn(x, params)\n",
        "    - params: List of PyTorch Tensors giving parameters of the model\n",
        "\n",
        "    Returns: Nothing, but prints the accuracy of the model\n",
        "    \"\"\"\n",
        "    split = 'val' if istrain else 'test'\n",
        "    print('Checking accuracy on the %s set' % split)\n",
        "    num_correct, num_samples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.int64)\n",
        "            scores = model_fn(x, params)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwNMOvc7pR1-"
      },
      "source": [
        "### BareBones PyTorch: Training Loop\n",
        "ì´ì œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•œ basic training loopë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. momentum ì—†ì´ Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `torch.functional.cross_entropy`ë¥¼ ì‚¬ìš©í•˜ì—¬ lossë¥¼ ê³„ì‚°í•  ê²ƒì…ë‹ˆë‹¤(http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
        "\n",
        "training loopëŠ” ì‹ ê²½ë§ í•¨ìˆ˜, ì´ˆê¸°í™”ëœ ë§¤ê°œë³€ìˆ˜ ëª©ë¡(ì˜ˆì œì—ì„œëŠ” `[w1, w2]`), í•™ìŠµ ì†ë„ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyt2Boy_pR1-"
      },
      "outputs": [],
      "source": [
        "def train_part2(model_fn, params, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a model on MNIST.\n",
        "\n",
        "    Inputs:\n",
        "    - model_fn: A Python function that performs the forward pass of the model.\n",
        "      It should have the signature scores = model_fn(x, params) where x is a\n",
        "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
        "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
        "      scores for the elements in x.\n",
        "    - params: List of PyTorch Tensors giving weights for the model\n",
        "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
        "\n",
        "    Returns: Nothing\n",
        "    \"\"\"\n",
        "    for t, (x, y) in enumerate(train_dataloader):\n",
        "        # Move the data to the proper device (GPU or CPU)\n",
        "        x = x.to(device=device, dtype=dtype)\n",
        "        y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "        # Forward pass: compute scores and loss\n",
        "        scores = model_fn(x, params)\n",
        "        loss = F.cross_entropy(scores, y)\n",
        "\n",
        "        # Backward pass: PyTorch figures out which Tensors in the computational\n",
        "        # graph has requires_grad=True and uses backpropagation to compute the\n",
        "        # gradient of the loss with respect to these Tensors, and stores the\n",
        "        # gradients in the .grad attribute of each Tensor.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters. We don't want to backpropagate through the\n",
        "        # parameter updates, so we scope the updates under a torch.no_grad()\n",
        "        # context manager to prevent a computational graph from being built.\n",
        "        with torch.no_grad():\n",
        "            for w in params:\n",
        "                w -= learning_rate * w.grad\n",
        "\n",
        "                # Manually zero the gradients after running the backward pass\n",
        "                w.grad.zero_()\n",
        "\n",
        "        if t % print_every == 0:\n",
        "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "            check_accuracy_part2(val_dataloader, model_fn, params)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhZfY1PzpR1_"
      },
      "source": [
        "### BareBones PyTorch: Train a Two-Layer Network\n",
        "ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. fully connected weightsì¸ `w1`ê³¼ `w2`ì— ëŒ€í•œ Tensorë¥¼ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "MNISTì˜ ê° minibatchì—ëŠ” 64ê°œì˜ ì˜ˆê°€ ìˆìœ¼ë¯€ë¡œ í…ì„œ ëª¨ì–‘ì€ `[64, 1, 28, 28]`ì…ë‹ˆë‹¤.\n",
        "\n",
        "flatten í›„ `x` ëª¨ì–‘ì€ `[64, 1 * 28 * 28]`ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì´ `w1`ì˜ ì²« ë²ˆì§¸ ì°¨ì› í¬ê¸°ê°€ ë©ë‹ˆë‹¤.\n",
        "`w1`ì˜ ë‘ ë²ˆì§¸ ì°¨ì›ì€ hidden layer sizeì´ë©°, ì´ëŠ” ë˜í•œ `w2`ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ ì¶œë ¥ì€ 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 10ì°¨ì› ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "hyperparameterë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ í•œ íšŒê¸° ë™ì•ˆ í›ˆë ¨í•œ í›„ì—ëŠ” 40% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVhigckkpR1_"
      },
      "outputs": [],
      "source": [
        "hidden_layer_size = 64\n",
        "learning_rate = 1e-2\n",
        "\n",
        "w1 = random_weight((1 * 28 * 28, hidden_layer_size))\n",
        "w2 = random_weight((hidden_layer_size, 10))\n",
        "\n",
        "train_part2(two_layer_fc, [w1, w2], learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpzU23oApR2A"
      },
      "source": [
        "# Part IV. PyTorch Module API\n",
        "\n",
        "Barebone PyTorchì—ì„œëŠ” ëª¨ë“  Parameter tensorsë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ëª‡ ê°œì˜ í…ì„œê°€ ìˆëŠ” ì†Œê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ê´œì°®ì§€ë§Œ, ëŒ€ê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œ ìˆ˜ì‹­ ë˜ëŠ” ìˆ˜ë°± ê°œì˜ í…ì„œë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¶ˆí¸í•˜ê³  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.\n",
        "\n",
        "PyTorchëŠ” ì„ì˜ì˜ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•˜ëŠ” ë™ì‹œì— í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ `nn.Module` APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. Part IIì—ì„œëŠ” SGDë¥¼ ì§ì ‘ êµ¬í˜„í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. PyTorchëŠ” ë˜í•œ RMSProp, Adagrad, Adamê³¼ ê°™ì€ ëª¨ë“  ì¼ë°˜ì ì¸ Optimizerë¥¼ êµ¬í˜„í•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹¬ì§€ì–´ L-BFGSì™€ ê°™ì€ ëŒ€ëµì ì¸ 2ì°¨ ë°©ë²•ë„ ì§€ì›í•©ë‹ˆë‹¤! ê° ì˜µí‹°ë§ˆì´ì €ì˜ ì •í™•í•œ ì‚¬ì–‘ì€ [ë¬¸ì„œ](http://pytorch.org/docs/master/optim.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "\n",
        "ëª¨ë“ˆ APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\n",
        "\n",
        "1. ì„œë¸Œí´ë˜ìŠ¤ `nn.Module`. ë„¤íŠ¸ì›Œí¬ í´ë˜ìŠ¤ì— `TwoLayerFC`ì™€ ê°™ì€ ì§ê´€ì ì¸ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ìƒì„±ì `__init__()`ì—ì„œ í•„ìš”í•œ ëª¨ë“  ë ˆì´ì–´ë¥¼ í´ë˜ìŠ¤ ì†ì„±ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. `nn.Linear` ë° `nn.Conv2d`ì™€ ê°™ì€ ë ˆì´ì–´ ê°ì²´ëŠ” ê·¸ ìì²´ë¡œ `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ì´ë©° í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ë¯€ë¡œ ì›ì‹œ í…ì„œë¥¼ ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤í™”í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. `nn.Module`ì´ ì´ëŸ¬í•œ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ìˆ˜ì‹­ ê°œì˜ ë‚´ì¥ ë ˆì´ì–´ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ [ë¬¸ì„œ](http://pytorch.org/docs/master/nn.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. **ê²½ê³ **: `super().__init__()`ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!\n",
        "\n",
        "3. `forward()` ë©”ì„œë“œì—ì„œ ë„¤íŠ¸ì›Œí¬ì˜ *ì—°ê²°ì„±*ì„ ì •ì˜í•©ë‹ˆë‹¤. í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  \"ë³€í™˜ëœ\" í…ì„œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œë¡œ `__init__`ì— ì •ì˜ëœ ì†ì„±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. `forward()`ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ê°€ ìˆëŠ” ìƒˆ ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”! ëª¨ë“  ë§¤ê°œë³€ìˆ˜ëŠ” `__init__`ì—ì„œ ë¯¸ë¦¬ ì„ ì–¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë“ˆ ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ê°ì²´ë¡œ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ Part IIì˜ NN ì „ë‹¬ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### Module API: Two-Layer Network\n",
        "ë‹¤ìŒì€ fully connected 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì²´ì ì¸ ì˜ˆì…ë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSrvts7LpR2A"
      },
      "outputs": [],
      "source": [
        "class TwoLayerFC(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        # assign layer objects to class attributes\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # nn.init package contains convenient initialization methods\n",
        "        # http://pytorch.org/docs/master/nn.html#torch-nn-init\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        nn.init.kaiming_normal_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward always defines connectivity\n",
        "        x = flatten(x)\n",
        "        scores = self.fc2(F.relu(self.fc1(x)))\n",
        "        return scores\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    input_size = 50\n",
        "    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
        "    model = TwoLayerFC(input_size, 42, 10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "test_TwoLayerFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3CDip-7pR2B"
      },
      "source": [
        "### Module API: Check Accuracy\n",
        "ê²€ì¦ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì£¼ì–´ì§€ë©´ ì‹ ê²½ë§ì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë²„ì „ì€ Part IIì˜ ë²„ì „ê³¼ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤. ë” ì´ìƒ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì „ë‹¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PYAZQ1DpR2B"
      },
      "outputs": [],
      "source": [
        "def check_accuracy_part34(loader, model, istrain = True):\n",
        "    if istrain:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb6341vOpR2B"
      },
      "source": [
        "### ë¬¸ì œ 11. Module API: Training Loop\n",
        "ë˜í•œ ì•½ê°„ ë‹¤ë¥¸ training loopë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ê°’ì„ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹ , Optimization ì•Œê³ ë¦¬ì¦˜ì˜ ê°œë…ì„ ì¶”ìƒí™”í•˜ê³  ì‹ ê²½ë§ ìµœì í™”ì— ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ì„ ì œê³µí•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ì˜ Optimizer ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY-B6AXbpR2B"
      },
      "outputs": [],
      "source": [
        "def train_part34(model, optimizer, epochs=2):\n",
        "    \"\"\"\n",
        "    Train a model on MNIST using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(train_dataloader):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ################################################################################\n",
        "            # TODO: get model output and calculate cross entropy loss                      #\n",
        "            ################################################################################\n",
        "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "            pass\n",
        "\n",
        "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "            ################################################################################\n",
        "            #                                 END OF YOUR CODE                             #\n",
        "            ################################################################################\n",
        "\n",
        "\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(val_dataloader, model)\n",
        "                print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMFEsm-OpR2C"
      },
      "source": [
        "### Module API: Train a Two-Layer Network\n",
        "ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. Part IIì™€ ë‹¬ë¦¬ ì´ë²ˆì—ëŠ” Parameter tensorsë¥¼ ë” ì´ìƒ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì…ë ¥ í¬ê¸°, ìˆ¨ê²¨ì§„ ë ˆì´ì–´ í¬ê¸°, í´ë˜ìŠ¤ ìˆ˜(ì¦‰, ì¶œë ¥ í¬ê¸°)ë¥¼ `TwoLayerFC`ì˜ ìƒì„±ìì— ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ `TwoLayerFC` ë‚´ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ epoch ë™ì•ˆ í•™ìŠµí•œ í›„ 40% ì´ìƒì˜ ëª¨ë¸ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCwaZfJTpR2C"
      },
      "outputs": [],
      "source": [
        "hidden_layer_size = 64\n",
        "learning_rate = 1e-2\n",
        "model = TwoLayerFC(784, hidden_layer_size, 10)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_part34(model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsFqIP43pR2D"
      },
      "source": [
        "# ë¬¸ì œ 12. Part V. PyTorch Sequential API\n",
        "\n",
        "Part IVì—ì„œëŠ” ì„ì˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë ˆì´ì–´ì™€ ê·¸ ì—°ê²°ì„±ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” PyTorch ëª¨ë“ˆ APIë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Feed forward layersê³¼ ê°™ì€ ê°„ë‹¨í•œ ëª¨ë¸ì˜ ê²½ìš°, `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , `__init__`ì—ì„œ í´ë˜ìŠ¤ ì†ì„±ì— ë ˆì´ì–´ë¥¼ í• ë‹¹í•˜ê³ , `forward()`ì—ì„œ ê° ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì”© í˜¸ì¶œí•˜ëŠ” 3ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. ë” í¸ë¦¬í•œ ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
        "\n",
        "ë‹¤í–‰íˆë„ PyTorchì—ì„œëŠ” ìœ„ì˜ ë‹¨ê³„ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ `nn.Sequential`ì´ë¼ëŠ” ì»¨í…Œì´ë„ˆ ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤. feed forward stacksë³´ë‹¤ ë” ë³µì¡í•œ topologyë¥¼ ì§€ì •í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— `nn.Module`ë§Œí¼ ìœ ì—°í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ë§ì€ ì‚¬ìš© ì‚¬ë¡€ì— ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Sequential API: 3ê³„ì¸µ ë„¤íŠ¸ì›Œí¬\n",
        "`nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ 3ê³„ì¸µ fully connected ë„¤íŠ¸ì›Œí¬ ì˜ˆì œë¥¼ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ìœ„ì—ì„œ ì •ì˜í•œ training loopë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ì‹œë‹¤.\n",
        "\n",
        "\n",
        "1. output dimensionì´ 256ì¸ fully-coonected layer\n",
        "2. ReLU\n",
        "3. output dimensionì´ 64ì¸ fully-coonected layer\n",
        "4. ReLU\n",
        "5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ fully-coonected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTN-_2OmpR2D"
      },
      "outputs": [],
      "source": [
        "# We need to wrap `flatten` function in a module in order to stack it\n",
        "# in nn.Sequential\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return flatten(x)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model = nn.Sequential(\n",
        "    ################################################################################\n",
        "    # TODO                                                                         #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ################################################################################\n",
        "    #                                 END OF YOUR CODE                             #\n",
        "    ################################################################################\n",
        ")\n",
        "\n",
        "# you can use Nesterov momentum in optim.SGD\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_part34(model, optimizer, epochs = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0RoJmFvy9TH"
      },
      "source": [
        "# ë¬¸ì œ 13. Part VI. ê²°ê³¼ë¶„ì„\n",
        "\n",
        "* ì—¬ëŸ¬ë¶„ë“¤ì´ ë°©ê¸ˆ ë§Œë“  modelì€ 3ê³„ì¸µ MLP ëª¨ë¸ì…ë‹ˆë‹¤. ì²˜ìŒ ë°ì´í„° ë¶„ì„ì—ì„œ t-SNEë¥¼ í™œìš©í•˜ì—¬, imageë¥¼ projection í–ˆë˜ ê²ƒ ê¸°ì–µí•˜ì‹œë‚˜ìš”? ì´ë²ˆì—ëŠ” ê° ê³„ì¸µì˜ ê²°ê³¼ê°’ë§ˆë‹¤ projectionì„ ì ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•´ë´…ì‹œë‹¤.\n",
        "\n",
        "* ì €í¬ì˜ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì´ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
        "  1. output dimensionì´ 256ì¸ fully-coonected layer\n",
        "  2. ReLU\n",
        "  3. output dimensionì´ 64ì¸ fully-coonected layer\n",
        "  4. ReLU\n",
        "  5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ fully-coonected layer\n",
        "\n",
        "* ì²«ë²ˆì§¸ ì½”ë“œëŠ” image ìì²´ë¥¼ projectioní•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
        "* ë‘ë²ˆì§¸ ì½”ë“œëŠ” modelì— 1ë²ˆê¹Œì§€ ì ìš©í•˜ê³  ë‚˜ì˜¨ 256-dimension ì¶œë ¥ê°’ìš¸ projectioní•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
        "* ì„¸ë²ˆì§¸ ì½”ë“œëŠ” modelì— 3ë²ˆê¹Œì§€ ì ìš©í•˜ê³  ë‚˜ì˜¨ 64-dimension ì¶œë ¥ê°’ì„ projectioní•œ ê²°ê³¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_ApiXPUDWs7"
      },
      "outputs": [],
      "source": [
        "intermediate_model = nn.Sequential(nn.Flatten())\n",
        "\n",
        "# Prepare the data\n",
        "n_samples = 2000\n",
        "total = 0\n",
        "intermediate_output = []\n",
        "tmp_labels = []\n",
        "for data in test_dataloader:\n",
        "  images, labels = data\n",
        "  intermediate_output.extend(intermediate_model(images).cpu().detach().numpy())\n",
        "  tmp_labels.extend(labels)\n",
        "\n",
        "intermediate_output = np.array(intermediate_output)\n",
        "tmp_labels = np.array(tmp_labels)\n",
        "\n",
        "indices = np.random.choice(len(intermediate_output), n_samples, replace=False)\n",
        "images_subset = intermediate_output[indices]\n",
        "labels_subset = tmp_labels[indices]\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(images_subset)\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(12, 8))\n",
        "for label in np.unique(labels_subset):\n",
        "    indices = labels_subset == label\n",
        "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE projection of MNIST dataset (784-dimensional embeddings)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSGrnr3xDYe_"
      },
      "outputs": [],
      "source": [
        "intermediate_model = nn.Sequential(*list(model.children())[:-4])\n",
        "\n",
        "# Prepare the data\n",
        "n_samples = 2000\n",
        "total = 0\n",
        "intermediate_output = []\n",
        "tmp_labels = []\n",
        "for data in test_dataloader:\n",
        "  images, labels = data\n",
        "  images = images.to(device)\n",
        "  intermediate_output.extend(intermediate_model(images).cpu().detach().numpy())\n",
        "  tmp_labels.extend(labels)\n",
        "\n",
        "intermediate_output = np.array(intermediate_output)\n",
        "tmp_labels = np.array(tmp_labels)\n",
        "\n",
        "indices = np.random.choice(len(intermediate_output), n_samples, replace=False)\n",
        "images_subset = intermediate_output[indices]\n",
        "labels_subset = tmp_labels[indices]\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(images_subset)\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(12, 8))\n",
        "for label in np.unique(labels_subset):\n",
        "    indices = labels_subset == label\n",
        "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE projection of MNIST dataset (256-dimensional embeddings)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0UwsEZrDZrk"
      },
      "outputs": [],
      "source": [
        "intermediate_model = nn.Sequential(*list(model.children())[:-2])\n",
        "\n",
        "# Prepare the data\n",
        "n_samples = 2000\n",
        "total = 0\n",
        "intermediate_output = []\n",
        "tmp_labels = []\n",
        "for data in test_dataloader:\n",
        "  images, labels = data\n",
        "  images = images.to(device)\n",
        "  intermediate_output.extend(intermediate_model(images).cpu().detach().numpy())\n",
        "  tmp_labels.extend(labels)\n",
        "\n",
        "intermediate_output = np.array(intermediate_output)\n",
        "tmp_labels = np.array(tmp_labels)\n",
        "\n",
        "indices = np.random.choice(len(intermediate_output), n_samples, replace=False)\n",
        "images_subset = intermediate_output[indices]\n",
        "labels_subset = tmp_labels[indices]\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(images_subset)\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(12, 8))\n",
        "for label in np.unique(labels_subset):\n",
        "    indices = labels_subset == label\n",
        "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE projection of MNIST dataset (64-dimensional embeddings)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8kwaunfDbij"
      },
      "source": [
        "**ë¬¸ì œ 13**\n",
        "\n",
        "ê²°ê³¼ë¥¼ ë¶„ì„í•´ë³´ì„¸ìš”! :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqeyS5NPrYcL"
      },
      "source": [
        "# ë¬¸ì œ 14, 15, 16. Part VII. Optimizer\n",
        "\n",
        "* Optimizerì—ëŠ” êµ‰ì¥íˆ ë§ì€ ì¢…ë¥˜ê°€ ìˆì£ . ì €í¬ëŠ” ì˜¤ëŠ˜ ê·¸ ì¤‘ì—ì„œ SGD / Momentum / RMSprop / Adam ì´ë ‡ê²Œ 4ê°œì˜ optimizerë¥¼ ë¹„êµí•´ ë³´ë ¤ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "* ê²°ê³¼ë¥¼ ì‹œê°í™”í•œ ìë£Œë¥¼ ë³´ê³  ë§ˆìŒê» ë¶„ì„í•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRAB_E5Q1OnB"
      },
      "source": [
        "---\n",
        "SGDì™€ Momentumì„ ë¹„êµí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPsZkn6NYtKG"
      },
      "outputs": [],
      "source": [
        "def poly4_torch(x):\n",
        "    return 0.1 * x**4 - 0.5 * x**3 + 0.2 * x**2 + 2 * x + 1\n",
        "\n",
        "x_init = 4.0\n",
        "x_sgd = torch.tensor([x_init], requires_grad=True)\n",
        "x_momentum = torch.tensor([x_init], requires_grad=True)\n",
        "\n",
        "optimizer_sgd = optim.SGD([x_sgd], lr=0.01)\n",
        "optimizer_momentum = optim.SGD([x_momentum], lr=0.01, momentum=0.9)\n",
        "\n",
        "iterations = 1000\n",
        "\n",
        "x_values_sgd = [x_sgd.item()]\n",
        "x_values_momentum = [x_momentum.item()]\n",
        "\n",
        "loss_values_sgd = [poly4_torch(x_sgd).item()]\n",
        "loss_values_momentum = [poly4_torch(x_momentum).item()]\n",
        "\n",
        "for _ in range(iterations):\n",
        "\n",
        "    optimizer_sgd.zero_grad()\n",
        "    loss_sgd = poly4_torch(x_sgd)\n",
        "    loss_sgd.backward()\n",
        "    optimizer_sgd.step()\n",
        "    x_values_sgd.append(x_sgd.item())\n",
        "    loss_values_sgd.append(loss_sgd.item())\n",
        "\n",
        "    optimizer_momentum.zero_grad()\n",
        "    loss_momentum = poly4_torch(x_momentum)\n",
        "    loss_momentum.backward()\n",
        "    optimizer_momentum.step()\n",
        "    x_values_momentum.append(x_momentum.item())\n",
        "    loss_values_momentum.append(loss_momentum.item())\n",
        "\n",
        "x_range = torch.linspace(-2, 4, 500)\n",
        "y_range = poly4_torch(x_range).detach().numpy()\n",
        "\n",
        "def plot_optimizer(x_values, label, color):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(x_range, y_range, label='poly4_torch function', color='black')\n",
        "    plt.scatter(x_values, [poly4_torch(torch.tensor(x)).item() for x in x_values], label=label, color=color, alpha=0.5)\n",
        "    plt.xlabel('x value')\n",
        "    plt.ylabel('Loss value')\n",
        "    plt.title(f'Loss Function with {label} Optimization Steps')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_optimizer(x_values_sgd, 'SGD', 'green')\n",
        "plot_optimizer(x_values_momentum, 'Momentum', 'red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5R6d6fT1z--"
      },
      "source": [
        "**ë¬¸ì œ 14**\n",
        "\n",
        "* ë‹¤ìŒê³¼ ê°™ì€ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš” :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT0rQSJj1ujO"
      },
      "source": [
        "Momentumê³¼ Adamì„ ë¹„êµí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n-BTxlUYtgC"
      },
      "outputs": [],
      "source": [
        "def poly2d_torch(x, y):\n",
        "    return 0.15 * (x**4 + y**4) - 0.5 * (x**3 + y**3) + 0.2 * (x**2 + y**2) + 2 * (x + y) + 1\n",
        "\n",
        "x_init = torch.tensor([-2.0], requires_grad=True)\n",
        "y_init = torch.tensor([4.0], requires_grad=True)\n",
        "\n",
        "x_adam = x_init.clone().detach().requires_grad_(True)\n",
        "y_adam = y_init.clone().detach().requires_grad_(True)\n",
        "\n",
        "x_momentum = x_init.clone().detach().requires_grad_(True)\n",
        "y_momentum = y_init.clone().detach().requires_grad_(True)\n",
        "\n",
        "optimizer_adam = optim.Adam([x_adam, y_adam], lr=0.01)\n",
        "optimizer_momentum = optim.SGD([x_momentum, y_momentum], lr=0.01, momentum=0.9)\n",
        "\n",
        "iterations = 10000\n",
        "\n",
        "x_values_adam = [x_adam.item()]\n",
        "y_values_adam = [y_adam.item()]\n",
        "loss_values_adam = [poly2d_torch(x_adam, y_adam).item()]\n",
        "\n",
        "x_values_momentum = [x_momentum.item()]\n",
        "y_values_momentum = [y_momentum.item()]\n",
        "loss_values_momentum = [poly2d_torch(x_momentum, y_momentum).item()]\n",
        "\n",
        "for _ in tqdm(range(iterations)):\n",
        "    optimizer_adam.zero_grad()\n",
        "    loss_adam = poly2d_torch(x_adam, y_adam)\n",
        "    loss_adam.backward()\n",
        "    optimizer_adam.step()\n",
        "    x_values_adam.append(x_adam.item())\n",
        "    y_values_adam.append(y_adam.item())\n",
        "    loss_values_adam.append(loss_adam.item())\n",
        "\n",
        "    optimizer_momentum.zero_grad()\n",
        "    loss_momentum = poly2d_torch(x_momentum, y_momentum)\n",
        "    loss_momentum.backward()\n",
        "    optimizer_momentum.step()\n",
        "    x_values_momentum.append(x_momentum.item())\n",
        "    y_values_momentum.append(y_momentum.item())\n",
        "    loss_values_momentum.append(loss_momentum.item())\n",
        "\n",
        "x_range = torch.linspace(-2, 4, 100)\n",
        "y_range = torch.linspace(-2, 4, 100)\n",
        "X, Y = torch.meshgrid(x_range, y_range)\n",
        "Z = poly2d_torch(X, Y).detach().numpy()\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z, cmap='viridis', alpha=0.6)\n",
        "\n",
        "ax.scatter(x_values_adam, y_values_adam, loss_values_adam, label='Adam', color='orange')\n",
        "ax.scatter(x_values_momentum, y_values_momentum, loss_values_momentum, label='Momentum', color='red')\n",
        "\n",
        "ax.set_xlabel('x value')\n",
        "ax.set_ylabel('y value')\n",
        "ax.set_zlabel('Loss value')\n",
        "ax.set_title('Loss Function with Adam and Momentum Optimization Steps')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY3-7vN317LJ"
      },
      "source": [
        "**ë¬¸ì œ 15**\n",
        "\n",
        "* ë‹¤ìŒê³¼ ê°™ì€ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš” (ì¸í„°ë„·ì— ê²€ìƒ‰í•˜ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHmz5mYffFl2"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Training function\n",
        "def train_part34(model, criterion, optimizer, epochs=10):\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    train_loss = []\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(train_dataloader):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=torch.float)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = criterion(scores, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print(f'Epoch {e+1}, Iteration {t}, loss = {loss.item():.4f}')\n",
        "                train_loss.append(loss.item())\n",
        "    return train_loss\n",
        "\n",
        "# Initialize models and optimizers\n",
        "optimizers = {\n",
        "    'RMSProp': optim.RMSprop,\n",
        "    'Adam': optim.Adam,\n",
        "    'SGD': optim.SGD,\n",
        "    'Momentum': lambda params, lr: optim.SGD(params, lr=lr, momentum=0.9)\n",
        "}\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train models and collect loss\n",
        "losses = {}\n",
        "for opt_name, opt_class in optimizers.items():\n",
        "    print(f\"Training with {opt_name} optimizer\")\n",
        "    model = SimpleModel()\n",
        "    optimizer = opt_class(model.parameters(), lr=learning_rate)\n",
        "    losses[opt_name] = train_part34(model, criterion, optimizer)\n",
        "\n",
        "# Plotting the losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for opt_name, loss in losses.items():\n",
        "    plt.plot(loss, label=opt_name)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss with Different Optimizers')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3skNMwW2Brh"
      },
      "source": [
        "**ë¬¸ì œ 16**\n",
        "\n",
        "* ê²°ê³¼ë¥¼ ë§ˆìŒê» ë¶„ì„í•´ì£¼ì„¸ìš”:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH8oqtnTescU"
      },
      "source": [
        "# ë¬¸ì œ 17, 18.Part VIII ìì‹ ë§Œì˜ ëª¨ë¸ ë§Œë“¤ê¸°!\n",
        "\n",
        "* ì´ì œ ìœ„ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ììœ ë¡­ê²Œ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”!\n",
        "* 1ë“±í•˜ì‹œëŠ” ë¶„ê»˜ ê³¼ì œ ì œì‘ìì¸ 'ê¹€ë¯¼ì˜'ë‹˜ì´ ì»¤í”¼ ì¿ í°ì„ ë“œë¦½ë‹ˆë‹¤! (ê³µë™ 1ë“±  ì‹œ ë¨¼ì € ê³¼ì œë¥¼ ì œì¶œí•˜ì‹  ë¶„ê»˜ ì»¤í”¼ ì¿ í°ì„ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_fdwGwz301_"
      },
      "source": [
        "**ë¬¸ì œ 17**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU8o5MfEexI3"
      },
      "outputs": [],
      "source": [
        "learning_rate =\n",
        "model = nn.Sequential(\n",
        "\n",
        ")\n",
        "optimizer =\n",
        "epochs =\n",
        "\n",
        "train_part34(model, optimizer, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0pQLgSO3cLU"
      },
      "source": [
        "* ë°‘ì˜ ì½”ë“œì—ì„œ ë†’ì€ Scoreë¥¼ ì–»ìœ¼ì‹  ë¶„ì´ 1ë“±ì…ë‹ˆë‹¤. ìœ„ì—ëŠ” ì•„ë¬´ìƒê´€ì—†ìŠµë‹ˆë‹¤~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKzzT4qG2ROJ"
      },
      "outputs": [],
      "source": [
        "check_accuracy_part34(test_dataloader, model, istrain=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgnDIpAU3ntm"
      },
      "source": [
        "**ë¬¸ì œ 18**\n",
        "* ìì‹ ì˜ ëª¨ë¸ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeNWdsPu4KfV"
      },
      "source": [
        "## **ìˆ˜ê³  í•˜ì…¨ìŠµë‹ˆë‹¤~~**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vtsHWi7KpR1x",
        "aZQFg1RRpR11",
        "viZC941XecG6",
        "WtmHmtOPfFpz",
        "8QqUsPYBgXz_",
        "fkku-EHujvyc",
        "a7ZoDnoLlz6W",
        "gCsAL5_VmyUI",
        "m3YssC4pqNA0",
        "5Na9WUj8rMO6",
        "KLO6iHpBpR15",
        "UEL8vbVfu7rJ",
        "tsVplnGJuhDY",
        "G1mxlj_IvGf1",
        "tgkUWAzazIb3",
        "ISnEux55zXgQ",
        "OH8oqtnTescU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
